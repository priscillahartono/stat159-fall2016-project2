load("../../data/training-testing-sets.RData")
scaled_credit = na.omit(scaled_credit)
training_set = na.omit(training_set)
testing_set = na.omit(testing_set)
head(training_set)
pcr(Balance~., data=training_set, scale=FALSE, validation="CV")
summary(pcr(Balance~., data=training_set, scale=FALSE, validation="CV"))
pcr_best_model1 <- which.min(pcr_models$validation$PRESS)
head(testing_set)
head(testing_set[1])
testing_set[,-12]
pcr_predictions <- predict(pcr_models, ncomp =pcr_best_model1, newx=testing_set[,-12])
pcr_MSE <- mean((pcr_predictions - testing_set[,1:11])^2)
pcr_MSE
head(testing_set[,1:11])
x <- model.matrix(Balance ~ ., scaled_credit)[, 3:13]
x <- model.matrix(Balance ~ ., scaled_credit)[, -1]
head(x)
library(pls)
scaled_credit <- read.csv('../../data/scaled-credit.csv')
scaled_credit['X'] <- NULL
load("../../data/training-testing-sets.RData")
scaled_credit = na.omit(scaled_credit)
training_set = na.omit(training_set)
testing_set = na.omit(testing_set)
x <- model.matrix(Balance ~ ., scaled_credit)[, -1]
y <- scaled_credit$Balance
x_training <- model.matrix(Balance ~ ., training_set)[, 3:13]
y_training <- training_set$Balance
x_testing <- model.matrix(Balance ~ ., testing_set)[, 3:13]
y_testing <- testing_set$Balance
#Train Set (10-fold cross-validation)
#-------------------------------------
#PCR fitting function output models
set.seed(1)
pcr_models <- pcr(y_training~x_training, scale=FALSE, validation="CV")
#summary of PCR models
sum_pcr <- summary(pcr_models)
#"Best" fit model
pcr_best_model <- pcr_models$validation$PRESS
#smallest cross-validation occurs for component
pcr_best_model1 <- which.min(pcr_models$validation$PRESS)
#Generate visualization
#-------------------------------------
png("../../images/pcr-models-plot.png")
validationplot(pcr_models, val.type = "MSEP", main = "Cross-validation Errors for PCR")
dev.off()
#Test Set
#--------------------------------
#Get predictions for test set
pcr_predictions <- predict(pcr_models, ncomp =pcr_best_model1, newx=x_testing)
#Compute mean squared error
pcr_MSE <- mean((pcr_predictions - y_testing)^2)
#Refit PCR regression on full data set
#-----------------------------------------
full_data_pcr <- pcr(Balance ~ ., data=data.frame(scaled_credit), scale=FALSE, ncomp=pcr_best_model1)
#official coefficient estimates
pcr_fulldata_coef <- coef(full_data_pcr)
#Save file to RData
#-------------------
save(pcr_models, pcr_best_model1, pcr_predictions, pcr_MSE, full_data_pcr, pcr_fulldata_coef, file="../../data/principal-components-regression.RData")
x <- model.matrix(Balance ~ ., scaled_credit)[, -1]
head(x)
x_training <- model.matrix(Balance ~ ., training_set)[,-1]
head(x_training)
head(training_set)
head(traiing_set[-1])
head(traiing_set[,-1])
head(training_set[,-1])
x_training <- model.matrix(Balance ~ ., training_set)[,-1]
head(x_training)
x_training <- model.matrix(Balance ~ ., training_set)[,-1]
head(x_training)
head(training_set[,-1])
x_testing <- model.matrix(Balance ~ ., testing_set)[, -1]
head(x_testing)
library(pls)
scaled_credit <- read.csv('../../data/scaled-credit.csv')
scaled_credit['X'] <- NULL
load("../../data/training-testing-sets.RData")
scaled_credit = na.omit(scaled_credit)
training_set = na.omit(training_set)
testing_set = na.omit(testing_set)
x <- model.matrix(Balance ~ ., scaled_credit)[, -1]
y <- scaled_credit$Balance
x_training <- model.matrix(Balance ~ ., training_set)[,-1]
y_training <- training_set$Balance
x_testing <- model.matrix(Balance ~ ., testing_set)[, -1]
y_testing <- testing_set$Balance
#Train Set (10-fold cross-validation)
#-------------------------------------
#PCR fitting function output models
set.seed(1)
pcr_models <- pcr(y_training~x_training, scale=FALSE, validation="CV")
#summary of PCR models
sum_pcr <- summary(pcr_models)
#"Best" fit model
pcr_best_model <- pcr_models$validation$PRESS
#smallest cross-validation occurs for component
pcr_best_model1 <- which.min(pcr_models$validation$PRESS)
#Generate visualization
#-------------------------------------
png("../../images/pcr-models-plot.png")
validationplot(pcr_models, val.type = "MSEP", main = "Cross-validation Errors for PCR")
dev.off()
#Test Set
#--------------------------------
#Get predictions for test set
pcr_predictions <- predict(pcr_models, ncomp=pcr_best_model1, newdata=x_testing)
#Compute mean squared error
pcr_MSE <- mean((pcr_predictions - y_testing)^2)
pcr_MSE
#Refit PCR regression on full data set
#-----------------------------------------
full_data_pcr <- pcr(Balance ~ ., data=data.frame(scaled_credit), scale=FALSE, ncomp=pcr_best_model1)
#official coefficient estimates
pcr_fulldata_coef <- coef(full_data_pcr)
#Save file to RData
#-------------------
save(pcr_models, pcr_best_model1, pcr_predictions, pcr_MSE, full_data_pcr, pcr_fulldata_coef, file="../../data/principal-components-regression.RData")
library(pls)
scaled_credit <- read.csv('../../data/scaled-credit.csv')
scaled_credit['X'] <- NULL
load("../../data/training-testing-sets.RData")
scaled_credit = na.omit(scaled_credit)
training_set = na.omit(training_set)
testing_set = na.omit(testing_set)
x <- model.matrix(Balance ~ ., scaled_credit)[, -1]
y <- scaled_credit$Balance
x_training <- model.matrix(Balance ~ ., training_set)[,-1]
y_training <- training_set$Balance
x_testing <- model.matrix(Balance ~ ., testing_set)[, -1]
y_testing <- testing_set$Balance
#Train Set (10-fold cross-validation)
#-------------------------------------
#PCR fitting function output models
set.seed(1)
pcr_models <- pcr(y_training~x_training, scale=FALSE, validation="CV")
#summary of PCR models
sum_pcr <- summary(pcr_models)
#"Best" fit model
pcr_best_model <- pcr_models$validation$PRESS
#smallest cross-validation occurs for component
pcr_best_model1 <- which.min(pcr_models$validation$PRESS)
#Generate visualization
#-------------------------------------
png("../../images/pcr-models-plot.png")
validationplot(pcr_models, val.type = "MSEP", main = "Cross-validation Errors for PCR")
dev.off()
#Test Set
#--------------------------------
#Get predictions for test set
pcr_predictions <- predict(pcr_models, ncomp=pcr_best_model1, newdata=x_testing)
#Compute mean squared error
pcr_MSE <- mean((pcr_predictions - y_testing)^2)
#Refit PCR regression on full data set
#-----------------------------------------
full_data_pcr <- pcr(Balance ~ ., data=data.frame(scaled_credit), scale=FALSE, ncomp=pcr_best_model1)
#official coefficient estimates
pcr_fulldata_coef <- coef(full_data_pcr)
#Save file to RData
#-------------------
save(pcr_models, pcr_best_model1, pcr_predictions, pcr_MSE, full_data_pcr, pcr_fulldata_coef, file="../../data/principal-components-regression.RData")
pcr_MSE
library(pls)
scaled_credit <- read.csv('../../data/scaled-credit.csv')
scaled_credit['X'] <- NULL
load("../../data/training-testing-sets.RData")
scaled_credit = na.omit(scaled_credit)
training_set = na.omit(training_set)
testing_set = na.omit(testing_set)
x <- model.matrix(Balance ~ ., scaled_credit)[, -1]
y <- scaled_credit$Balance
x_training <- model.matrix(Balance ~ ., training_set)[,-1]
y_training <- training_set$Balance
x_testing <- model.matrix(Balance ~ ., testing_set)[, -1]
y_testing <- testing_set$Balance
#Train Set (10-fold cross-validation)
#-------------------------------------
#PCR fitting function output models
set.seed(1)
pcr_models <- pcr(y_training~x_training, scale=FALSE, validation="CV")
#summary of PCR models
sum_pcr <- summary(pcr_models)
#"Best" fit model
pcr_best_model <- pcr_models$validation$PRESS
#smallest cross-validation occurs for component
pcr_best_model1 <- which.min(pcr_models$validation$PRESS)
#Generate visualization
#-------------------------------------
png("../../images/pcr-models-plot.png")
validationplot(pcr_models, val.type = "MSEP", main = "Cross-validation Errors for PCR")
dev.off()
#Test Set
#--------------------------------
#Get predictions for test set
pcr_predictions <- predict(pcr_models, ncomp=pcr_best_model1, newdata=x_testing)
#Compute mean squared error
pcr_MSE <- mean((pcr_predictions - y_testing)^2)
#Refit PCR regression on full data set
#-----------------------------------------
full_data_pcr <- pcr(Balance ~ ., data=data.frame(scaled_credit), scale=FALSE, ncomp=pcr_best_model1)
#official coefficient estimates
pcr_fulldata_coef <- coef(full_data_pcr)
#Save file to RData
#-------------------
save(pcr_models, pcr_best_model1, pcr_predictions, pcr_MSE, full_data_pcr, pcr_fulldata_coef, file="../../data/principal-components-regression.RData")
# install.packages('pls')
library(pls)
scaled_credit <- read.csv('../../data/scaled-credit.csv')
scaled_credit['X'] <- NULL
load('../../data/training-testing-sets.RData')
scaled_credit = na.omit(scaled_credit)
training_set = na.omit(training_set)
testing_set = na.omit(testing_set)
scaled_credit_x = model.matrix(Balance ~ ., scaled_credit)[, -1]
scaled_credit_y = scaled_credit$Balance
training_set_x = model.matrix(Balance ~ ., training_set)[,-1]
training_set_y = training_set$Balance
testing_set_x = model.matrix(Balance ~ ., testing_set)[, -1]
testing_set_y = testing_set$Balance
#Train Set (10-fold cross-validation)
#-------------------------------------
#PLSR fitting function output models
#Generate visualization
#-------------------------------------
set.seed(1)
plsr_fit <- plsr(training_set_y~training_set_x, scale=FALSE, validation="CV")
png("../../images/plsr-models-plot.png")
validationplot(plsr_fit, val.type = "MSEP", main = "Cross-validation Errors for PLSR")
dev.off()
#"Best" fit model
plsr_best_model <- plsr_models$validation$PRESS
#smallest cross-validation occurs for component
plsr_best_model1 <- which.min(plsr_models$validation$PRESS)
#Test Set
#--------------------------------
#Get predictions for test set
plsr_pred <- predict(plsr_fit, ncomp=plsr_best_model1, newdata=testing_set_x)
#Compute mean squared error
plsr_mean <- mean((plsr_pred - testing_set_y)^2)
#Refit PLSR regression on full data set
#-----------------------------------------
plsr_out <- plsr(scaled_credit_y~scaled_credit_x, scale=FALSE, ncomp=plsr_best_model1)
#official coefficient estimates
plsr_coef <- coef(plsr_out)
#Save file to RData
#-------------------
save(plsr_models, plsr_best_model1, plsr_pred, plsr_mean, plsr_out, plsr_coef, file="../../data/partial-least-squares-regression.RData")
plsr_mean
pcr_MSE
# install.packages('glmnet')
library(glmnet)
scaled_credit <- read.csv('../../data/scaled-credit.csv')
scaled_credit['X'] <-NULL
load("../../data/training-testing-sets.RData")
scaled_credit = na.omit(scaled_credit)
training_set = na.omit(training_set)
testing_set = na.omit(testing_set)
x <- model.matrix(Balance ~ ., scaled_credit)[, -1]
y <- scaled_credit$Balance
x_training <- model.matrix(Balance ~ ., training_set)[, -1]
y_training <- training_set$Balance
x_testing <- model.matrix(Balance ~ ., testing_set)[, -1]
y_testing <- testing_set$Balance
#Train Set (10-fold cross-validation)
#-------------------------------------
#Ridge fitting function output models
set.seed(100)
grid <- 10^seq(10, -2, length = 100)
ridge_models <- cv.glmnet(data.matrix(x_training), data.matrix(y_training),
alpha = 0,
lambda = grid,
nfolds = 10,
standardize = FALSE,
intercept = FALSE)
#"Best" model
ridge_best_model <- ridge_models$lambda.min
#Generate visualization
png("../../images/ridge-models-plot.png")
plot(ridge_models, main = "Plot of Ridge Models")
dev.off()
#Test Set
#--------------------------------
#Get predictions for test set
ridge_predictions <- predict(ridge_models, s = ridge_best_model, newx=x_testing)
#Compute mean squared error
ridge_MSE <- mean((ridge_predictions - y_testing)^2)
#Refit ridge regression on full data set
#-----------------------------------------
full_data_ridge <- glmnet(data.matrix(x), data.matrix(y),
alpha = 0,
lambda = ridge_best_model,
standardize = FALSE,
intercept = FALSE)
ridge_fulldata_coef <- coef(full_data_ridge)
#Save file
#--------------------------
save(ridge_models, ridge_best_model, ridge_predictions, ridge_MSE, full_data_ridge, ridge_fulldata_coef, file="../../data/ridge-regression.RData")
# install.packages('glmnet')
library(glmnet)
scaled_credit <- read.csv('../../data/scaled-credit.csv')
scaled_credit['X'] <- NULL
load('../../data/training-testing-sets.RData')
scaled_credit = na.omit(scaled_credit)
training_set = na.omit(training_set)
testing_set = na.omit(testing_set)
scaled_credit_x = model.matrix(Balance ~ ., scaled_credit)[, -1]
scaled_credit_y = scaled_credit$Balance
training_set_x = model.matrix(Balance ~ ., training_set)[, -1]
training_set_y = training_set$Balance
testing_set_x = model.matrix(Balance ~ ., testing_set)[, -1]
testing_set_y = testing_set$Balance
#Train Set (10-fold cross-validation)
#-------------------------------------
#Lasso fitting function output models
set.seed(123)
grid = 10^seq(10,-2, length = 100)
lasso_mod = glmnet(training_set_x, training_set_y, alpha = 1, lambda = grid)
plot(lasso_mod)
#Generate visualization
set.seed(1)
cv_lasso = cv.glmnet(training_set_x, training_set_y, alpha = 1, lambda = grid, intercept = FALSE, standardize = FALSE)
png('../../images/lasso-plot.png', main = "Plot of Lasso Models")
plot(cv_lasso)
dev.off()
#"Best" model
lasso_lam = cv_lasso$lambda.min
#Test Set
#--------------------------------
#Get predictions for test set
lasso_pred = predict(lasso_mod, s = lasso_lam, newx = testing_set_x)
#Compute mean squared error
lasso_mean = mean((lasso_pred - testing_set_y)^2)
#Refit lasso regression on full data set
#-----------------------------------------
lasso_out = glmnet(scaled_credit_x, scaled_credit_y, alpha = 1, lambda = grid)
lasso_coef = predict(lasso_out, type ="coefficients", s = lasso_lam )[2:12, ]
#Save file
#--------------------------
save(cv_lasso, lasso_lam, lasso_mean, lasso_coef, file='../../data/lasso-regression.RData')
scaled_credit <- read.csv('../../data/scaled-credit.csv')
scaled_credit['X'] <- NULL
#check for NA values
scaled_credit = na.omit(scaled_credit)
scaled_credit = data.frame(scaled_credit)
#Examining fit of dataset
#----------------------------------
ols<-lm(Balance ~ . ,
data=scaled_credit)
summary_ols <- summary(ols)
#Mean Squared Error
mse_ols <- mean(summary_ols$residuals^2)
#Coefficient of OLS
coef_ols <- coef(ols)
#Objects Saved in ols-regression.RData
#----------------------------------
save(ols, summary_ols, mse_ols, coef_ols, file = "../../data/ols-regression.RData")
#Generate ols-regression.txt
#----------------------------------
sink("../../data/ols-regression-output.txt")
cat("Ordinary Least Square\n")
print(ols)
cat("\n\n")
cat("Summary Statistics of OLS\n")
print(summary_ols)
cat("\n\n")
cat("Mean Squared Error (OLS)\n")
print(mse_ols)
cat("\n\n")
cat("Coefficients of OLS\n")
print(coef_ols)
sink()
---
output: pdf_document
---
```{r echo=FALSE, warning=FALSE}
library(png)
library(grid)
library(xtable)
library(ggplot2)
library(ggthemes)
library(reshape)
load('../../data/ols-regression.Rdata')
load('../../data/ridge-regression.RData')
load('../../data/lasso-regression.RData')
load('../../data/principal-components-regression.RData')
load('../../data/partial-least-squares-regression.RData')
load('../../data/correlation-matrix.RData')
```
# Results
Relationship: correlation matrix
Coeffs for all variables and model
```{r results='asis', message=FALSE, echo=FALSE, warning=FALSE}
o <-as.vector(coef_ols)
r <-as.vector(ridge_fulldata_coef)
l <-as.vector(lasso_coef)
pc <-as.vector(pcr_fulldata_coef)
pls <-as.vector(plsr_coef)
models_coef <- data.frame(
variables = c("Income", "Limit", "Rating", "Cards", "Age", "Education", "GenderFemale", "StudentYes", "MarriedYes", "EthnicityAsian", "EthnicityCaucasian"),
OLS = c(o[3], o[4], o[5], o[6], o[7], o[8], o[9], o[10], o[11], o[12], o[13]),
Ridge = c(r[2], r[3], r[4], r[5], r[6], r[7], r[8], r[9], r[10], r[11], r[12]),
Lasso = c(l[2], l[3], l[4], l[5], l[6], l[7], l[8], l[9], l[10], l[11], l[12]),
PCR = c(pc[2], pc[3], pc[4], pc[5], pc[6], pc[7], pc[8], pc[9], pc[10], pc[11], pc[12]),
PLSR = c(pls[2], pls[3], pls[4], pls[5], pls[6], pls[7], pls[8], pls[9], pls[10], pls[11], pls[12])
)
models_coef[is.na(models_coef)] <- 0
coef_models <- xtable(models_coef, digits=4, caption="Coefficient Estimates for all models")
print(coef_models, type="latex", comment=FALSE, caption.placement='top')
```
Table with each model's MSE.
```{r results='asis', message=FALSE, echo=FALSE, warning=FALSE}
merged_mse <- data.frame(
Model = c("OLS", "Ridge", "Lasso", "PCR", "PLS"),
MSE = c(mse_ols, ridge_MSE, lasso_mean, pcr_MSE, plsr_mean))
mse_models <- xtable(merged_mse, digits=4, caption="MSE for all models")
print(mse_models, type="latex", comment=FALSE, caption.placement='top')
```
```{r message=FALSE, echo=FALSE, warning=FALSE}
method_coef <- melt(models_coef, id="variables")
names(method_coef)[1] <- "Predictors"
names(method_coef)[2] <- "Method"
names(method_coef)[3] <- "Value"
ggplot(data=method_coef, aes(x=Predictors, y=Value)) +
geom_bar(stat="identity") +
facet_grid(~Method)+
theme(axis.text.x = element_text(angle = 90, hjust = 0.5))
```
OLS = c(o[3], o[4], o[5], o[6], o[7], o[8], o[9], o[10], o[11], o[12], o[13])
o <-as.vector(coef_ols)
o
coef_ols
ridge_fulldata_coef
ridge_fulldata_coef[1]
ridge_fulldata_coef[2]
lasso_coef
as.factor(lasso_coef)
lasso_coef[1]
pcr_fulldata_coef
library(pls)
scaled_credit <- read.csv('../../data/scaled-credit.csv')
scaled_credit['X'] <- NULL
load("../../data/training-testing-sets.RData")
scaled_credit = na.omit(scaled_credit)
training_set = na.omit(training_set)
testing_set = na.omit(testing_set)
x <- model.matrix(Balance ~ ., scaled_credit)[, -1]
y <- scaled_credit$Balance
x_training <- model.matrix(Balance ~ ., training_set)[,-1]
y_training <- training_set$Balance
x_testing <- model.matrix(Balance ~ ., testing_set)[, -1]
y_testing <- testing_set$Balance
#Train Set (10-fold cross-validation)
#-------------------------------------
#PCR fitting function output models
set.seed(1)
pcr_models <- pcr(y_training~x_training, scale=FALSE, validation="CV")
#summary of PCR models
sum_pcr <- summary(pcr_models)
#"Best" fit model
pcr_best_model <- pcr_models$validation$PRESS
#smallest cross-validation occurs for component
pcr_best_model1 <- which.min(pcr_models$validation$PRESS)
#Generate visualization
#-------------------------------------
png("../../images/pcr-models-plot.png")
validationplot(pcr_models, val.type = "MSEP", main = "Cross-validation Errors for PCR")
dev.off()
#Test Set
#--------------------------------
#Get predictions for test set
pcr_predictions <- predict(pcr_models, ncomp=pcr_best_model1, newdata=x_testing)
#Compute mean squared error
pcr_MSE <- mean((pcr_predictions - y_testing)^2)
#Refit PCR regression on full data set
#-----------------------------------------
full_data_pcr <- pcr(y~x, scale=FALSE, ncomp=pcr_best_model1)
#official coefficient estimates
pcr_fulldata_coef <- coef(full_data_pcr)
#Save file to RData
#-------------------
save(pcr_models, pcr_best_model1, pcr_predictions, pcr_MSE, full_data_pcr, pcr_fulldata_coef, file="../../data/principal-components-regression.RData")
---
output: pdf_document
---
```{r echo=FALSE, warning=FALSE}
library(png)
library(grid)
library(xtable)
library(ggplot2)
library(ggthemes)
library(reshape)
load('../../data/ols-regression.Rdata')
load('../../data/ridge-regression.RData')
load('../../data/lasso-regression.RData')
load('../../data/principal-components-regression.RData')
load('../../data/partial-least-squares-regression.RData')
load('../../data/correlation-matrix.RData')
```
pcr_fulldata_coef
pcr_fulldata_coef[1]
pls <-as.vector(plsr_coef)
pls
plsr_coef
library(png)
librar(grid)
library(grid)
library(xtable)
library(ggplot2)
library(ggthemes)
library(reshape)
